{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv2.findChessboardCorners() and cv2.drawChessboardCorners().\n",
    "\n",
    "1. Use **cv2.findChessboardCorners()** to find corners in chessboard images and aggregate arrays of image points (2D image plane points) and object points (3D world points).\n",
    "2. Use the OpenCV function **cv2.calibrateCamera()** to compute the calibration matrices and distortion coefficients.\n",
    "3. Use **cv2.undistort()** to undistort a test image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "nx = 8\n",
    "ny = 6\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((ny * nx,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('./Cal*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for idx, fname in enumerate(images):\n",
    "    img = mpimg.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "\n",
    "img = cv2.imread('test_image.jpg')\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "# Do camera calibration given object points and image points\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "\n",
    "# Perform undistortion\n",
    "undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "# Visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(undist)\n",
    "ax2.set_title('Undistorted Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Voxel Grid Downsampling\n",
    "\"pixel\" is short for \"picture element\". Similarly, the word \"voxel\" is short for \"volume element\".Each individual cell in the grid is now a voxel and the 3D grid is known as a \"voxel grid\".A voxel grid filter allows you to **downsample** the data by taking a spatial average of the points in the cloud confined by each voxel.\n",
    " Voxel Grid Downsampling section of RANSAC.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a VoxelGrid filter object for our input point cloud\n",
    "vox = cloud.make_voxel_grid_filter()\n",
    "\n",
    "# Choose a voxel (also known as leaf) size\n",
    "# Note: this (1) is a poor choice of leaf size   \n",
    "# Experiment and find the appropriate size!\n",
    "LEAF_SIZE = 1   \n",
    "\n",
    "# Set the voxel (or leaf) size  \n",
    "vox.set_leaf_size(LEAF_SIZE, LEAF_SIZE, LEAF_SIZE)\n",
    "\n",
    "# Call the filter function to obtain the resultant downsampled point cloud\n",
    "cloud_filtered = vox.filter()\n",
    "filename = 'voxel_downsampled.pcd'\n",
    "pcl.save(cloud_filtered, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 LEAF_SIZE implies your voxel is 1 cubic meter in volume. In practice, start with low and ho high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ros [image pipeline](http://wiki.ros.org/image_pipeline) For ros calibration you could visit this [link](http://wiki.ros.org/openni_launch/Tutorials/ExtrinsicCalibration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Pass Through Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "like a cropping tool it allows you to crop any given 3D point cloud by specifying an axis with cut-off values along that axis. The region you allow to pass through, is often referred to as region of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Sample Consensus or \"RANSAC\n",
    "use to identify points in your dataset that belong to a particular model.ie,a plane, a cylinder, a box, or any other common shape.\n",
    "\n",
    "If you have a prior knowledge of a certain shape being present in a given data set, you can use RANSAC to estimate what pieces of the point cloud set belong to that shape by assuming a particular model.\n",
    "\n",
    "Remove the tabel using it.\n",
    "\n",
    "### Disadvantage\n",
    "no upper limit on the time it can take to compute the model so can use \n",
    "\n",
    "fixed number of iterations but that has its own demerits as lower number of iterations, the solution obtained may not be optimal. \n",
    "\n",
    "Trade off compute time versus model detection accuracy.\n",
    "\n",
    "to determine traversable terrain, ground plane segmentation is an important part of a mobile robotâ€™s perception toolkit.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ransac\n",
    "two iteratively repeated steps on a given data set: Hypothesis and Verification. First, a hypothetical shape of the desired model is generated by randomly selecting a minimal subset of n-points and estimating the corresponding shape-model parameters.n=2 for line 3 for ==plane\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the segmentation object\n",
    "seg = cloud_filtered.make_segmenter()\n",
    "\n",
    "# Set the model you wish to fit \n",
    "seg.set_model_type(pcl.SACMODEL_PLANE)\n",
    "seg.set_method_type(pcl.SAC_RANSAC)\n",
    "\n",
    "# Max distance for a point to be considered fitting the model\n",
    "# Experiment with different values for max_distance \n",
    "# for segmenting the table\n",
    "max_distance = 1\n",
    "seg.set_distance_threshold(max_distance)\n",
    "\n",
    "# Call the segment function to obtain set of inlier indices and model coefficients\n",
    "inliers, coefficients = seg.segment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cloud_filtered' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-89097ca34241>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Extract inliers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mextracted_inliers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcloud_filtered\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minliers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'extracted_inliers.pcd'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpcl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextracted_inliers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cloud_filtered' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract inliers\n",
    "extracted_inliers = cloud_filtered.extract(inliers, negative=False)\n",
    "filename = 'extracted_inliers.pcd'\n",
    "pcl.save(extracted_inliers, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " extract method negative parameter to True for removing just the extracted object from the scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier removal filter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Much like the previous filters, we start by creating a filter object: \n",
    "outlier_filter = cloud_filtered.make_statistical_outlier_filter()\n",
    "\n",
    "# Set the number of neighboring points to analyze for any given point\n",
    "outlier_filter.set_mean_k(50)\n",
    "\n",
    "# Set threshold scale factor\n",
    "x = 1.0\n",
    "\n",
    "# Any point with a mean distance larger than global (mean distance+x*std_dev) will be considered outlier\n",
    "outlier_filter.set_std_dev_mul_thresh(x)\n",
    "\n",
    "# Finally call the filter function for magic\n",
    "cloud_filtered = outlier_filter.filter()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
